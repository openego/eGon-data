"""
Use the concept of dynamic line rating(DLR) to calculate temporal
depending capacity for HV transmission lines.
Inspired mainly on Planungsgrundsaetze-2020
Available at: 
<https://www.transnetbw.de/files/pdf/netzentwicklung/netzplanungsgrundsaetze/UENB_PlGrS_Juli2020.pdf>
"""
import geopandas as gpd
import pandas as pd
import numpy as np
from egon.data import db
import xarray as xr
import atlite
from shapely.geometry import Point
import psycopg2

def DLR_Regions(weather_info_path, regions_shape_path):
    
    #load, index and sort shapefile with the 9 regions defined by NEP 2020
    regions = gpd.read_file(regions_shape_path)
    regions = regions.set_index(["Region"])
    regions = regions.sort_values(by=["Region"])
    
    # download weather data from ERA-5 for Germany 2011
    cutout = atlite.Cutout("Germany-2011_era5",
                           cutout_dir = 'cutouts',
                           module="era5",
                           xs= slice(5., 16.),
                           ys=slice(56., 46.),
                           years= slice(2011, 2011)
                           )
    cutout.prepare()
        
    # The data downloaded using Atlite is divided by months. Paths_weather stores
    # the paths of the 12 files to be loaded together in 'weather_data_raw'. 
    paths_weather = []
    for i in range(1,13):
        paths_weather.append('cutouts/Germany-2011_era5/2011'+str(i).zfill(2)+'.nc') 
    weather_data_raw = xr.open_mfdataset(paths_weather)
    wind_speed_raw = weather_data_raw.wnd100m.values
    temperature_raw = weather_data_raw.temperature.values
    roughness_raw = weather_data_raw.roughness.values
    index = weather_data_raw.indexes._indexes
    # The info in 'weather_data_raw' has 3 dimensions. In 'weather_data' will be
    # stored all the relevant data in a 2 dimensions array.
    weather_data = np.zeros(shape=(wind_speed_raw.size, 5))
    count = 0
    for hour in range(index['time'].size):
        for row in range(index['y'].size):
            for column in range(index['x'].size):
                rough = roughness_raw[hour, row, column]
                ws_100m = wind_speed_raw[hour, row, column]
                #Use Log Law to calculate wind speed at 50m height
                ws_50m = ws_100m * (np.log(50/rough)/np.log(100/rough))
                weather_data[count, 0] = hour
                weather_data[count, 1] = index['y'][row]
                weather_data[count, 2] = index['x'][column]
                weather_data[count, 3] = ws_50m
                weather_data[count, 4] = temperature_raw[hour, row, column] - 273.15
                count += 1
    
    weather_data = pd.DataFrame(weather_data,
                                columns= ['hour', 'lat', 'lon', 'wind_s', 'temp'])
    
    region_selec = weather_data[0:index['x'].size*index['y'].size].copy()
    region_selec['geom'] = region_selec.apply(lambda x: Point(x['lon'], x['lat']), axis= 1)
    region_selec = gpd.GeoDataFrame(region_selec)
    region_selec = region_selec.set_geometry('geom')
    region_selec['region'] = np.zeros(index['x'].size*index['y'].size)
    
    #Mask weather information for each region defined by NEP 2020
    for reg in regions.index:
        weather_region = gpd.clip(region_selec, regions.loc[reg][0])
        region_selec['region'][region_selec.isin(weather_region).any(axis=1)] = reg
    
    weather_data['region'] = region_selec['region'].tolist()*index['time'].size
    weather_data = weather_data[weather_data['region'] != 0]
    
    #Create data frame to save results(Min wind speed, max temperature and %DLR per region along 8760h in a year)
    time = pd.date_range("2011-01-01", "2011-12-31 23:00:00", freq = "H")
    #time = time.transpose()
    dlr = pd.DataFrame(0, columns= ['R1-Wind_min', 'R1-Temp_max','R1-DLR',
                                    'R2-Wind_min', 'R2-Temp_max','R2-DLR',
                                    'R3-Wind_min', 'R3-Temp_max','R3-DLR',
                                    'R4-Wind_min', 'R4-Temp_max','R4-DLR',
                                    'R5-Wind_min', 'R5-Temp_max','R5-DLR',
                                    'R6-Wind_min', 'R6-Temp_max','R6-DLR',
                                    'R7-Wind_min', 'R7-Temp_max','R7-DLR',
                                    'R8-Wind_min', 'R8-Temp_max','R8-DLR',
                                    'R9-Wind_min', 'R9-Temp_max','R9-DLR'],
                                     index = time)
    
    #Calculate and save min wind speed and max temperature in a dataframe.
    #Since the dataframe generated by the function era5.weather_df_from_era5() is sorted by date,
    #it is faster to calculate the hourly results using blocks of data defined by "step", instead of
    #using a filter or a search function.
    for reg, df in weather_data.groupby(['region']):
        for t in range(0, len(time)):
            step = df.shape[0] / len(time)
            low_limit = int(t * step)
            up_limit = int(step*(t + 1))
            dlr.iloc[t,0+int(reg-1)*3] = min(df.iloc[low_limit:up_limit, 3])
            dlr.iloc[t,1+int(reg-1)*3] = max(df.iloc[low_limit:up_limit, 4])
    
    #The next loop use the min wind speed and max temperature calculated previously to
    #define the hourly DLR in for each region based on the table given by NEP 2020 pag 31
    for i in range(0, len(regions)):
        for j in range(0, len(time)):
            if dlr.iloc[j,1+i*3] <= 5:
                if dlr.iloc[j,0+i*3] < 3:
                    dlr.iloc[j,2+i*3] = 1.30
                elif dlr.iloc[j,0+i*3] < 4:
                    dlr.iloc[j,2+i*3] = 1.35
                elif dlr.iloc[j,0+i*3] < 5:
                    dlr.iloc[j,2+i*3] = 1.45
                else:
                    dlr.iloc[j,2+i*3] = 1.50
            elif dlr.iloc[j,1+i*3] <= 15:
                if dlr.iloc[j,0+i*3] < 3:
                    dlr.iloc[j,2+i*3] = 1.20
                elif dlr.iloc[j,0+i*3] < 4:
                    dlr.iloc[j,2+i*3] = 1.25
                elif dlr.iloc[j,0+i*3] < 5:
                    dlr.iloc[j,2+i*3] = 1.35
                elif dlr.iloc[j,0+i*3] < 6:
                    dlr.iloc[j,2+i*3] = 1.45
                else:
                    dlr.iloc[j,2+i*3] = 1.50
            elif dlr.iloc[j,1+i*3] <= 25:
                if dlr.iloc[j,0+i*3] < 3:
                    dlr.iloc[j,2+i*3] = 1.10
                elif dlr.iloc[j,0+i*3] < 4:
                    dlr.iloc[j,2+i*3] = 1.15
                elif dlr.iloc[j,0+i*3] < 5:
                    dlr.iloc[j,2+i*3] = 1.20
                elif dlr.iloc[j,0+i*3] < 6:
                    dlr.iloc[j,2+i*3] = 1.30
                else:
                    dlr.iloc[j,2+i*3] = 1.40
            elif dlr.iloc[j,1+i*3] <= 35:
                if dlr.iloc[j,0+i*3] < 3:
                    dlr.iloc[j,2+i*3] = 1.00
                elif dlr.iloc[j,0+i*3] < 4:
                    dlr.iloc[j,2+i*3] = 1.05
                elif dlr.iloc[j,0+i*3] < 5:
                    dlr.iloc[j,2+i*3] = 1.10
                elif dlr.iloc[j,0+i*3] < 6:
                    dlr.iloc[j,2+i*3] = 1.15
                else:
                    dlr.iloc[j,2+i*3] = 1.25
            else:
                dlr.iloc[j,2+i*3] = 1.00
    
    DLR_hourly_df_dic = {}
    for i in dlr.columns[range(2, 29, 3)]: # columns with DLR values
        DLR_hourly_df_dic[i] = dlr[i].values
    
    dlr_hourly = pd.DataFrame(index = time)
    for i in range(len(regions)):
        dlr_hourly['Reg_' + str(i+1)] = dlr.iloc[:, 3*i+2] 
        
    return DLR_hourly_df_dic, dlr_hourly


# The Lines_in_regions function generates a df with the nominal power and
# the region(s) in which each line is.
def Calculate_DLR():
    weather_info_path = 'cutouts/europe-2011-era5/201101.nc'
    regions_shape_path = 'DLR_regions/Germany_regions.shp'
    
    #Calculate hourly DLR per region
    dlr_hourly_dic, dlr_hourly = DLR_Regions(weather_info_path, regions_shape_path)
    
    regions = gpd.read_file(regions_shape_path)
    regions = regions.sort_values(by=["Region"])
    
    #Connect to the data base
    con = db.engine()
    sql = 'SELECT version, scn_name, line_id, geom, s_nom FROM grid.egon_pf_hv_line'
    df = gpd.GeoDataFrame.from_postgis(sql, con, crs = "EPSG:4326")
    df = df.set_index("line_id")
    trans_lines_R ={}
    for i in regions.Region:
        shape_area = regions[regions["Region"] == i]
        trans_lines_R[i] = gpd.clip(df, shape_area)        
    trans_lines= df[["s_nom"]]
    trans_lines["in_regions"] = [[] for i in range(len(df))]
    trans_lines[["version", "scn_name"]]= df[["version", "scn_name"]]
    
    for i in trans_lines_R:
        for j in trans_lines_R[i].index:
            trans_lines.loc[j][1] = trans_lines.loc[j][1].append(i)
    
    DLR = []
    # Assign to each transmision line the final values of DLR based on location
    # and type of line (overhead or underground) 
    for i in trans_lines.index:
    #lines completely out of the Germany border have DLR = 1
        if len(trans_lines.loc[i][1]) == 0: 
            DLR.append([1]*8760)
            continue
    # Underground lines have DLR = 1    
        if (trans_lines.loc[i][0] % 280 == 0 or 
            trans_lines.loc[i][0] % 550 == 0 or 
            trans_lines.loc[i][0] % 925 == 0):
            DLR.append([1]*8760)
            continue
    # Lines completely in one of the regions, have the DLR of the region   
        if len(trans_lines.loc[i][1]) == 1:
            region = int(trans_lines.loc[i][1][0])
            DLR.append(dlr_hourly_dic["R" + str(region) + '-DLR'])
            continue
    # For lines crossing 2 or more regions, the lowest DLR between the
    # different regions per hour is assigned.
        if len(trans_lines.loc[i][1]) > 1:
            reg = []
            for j in trans_lines.loc[i][1]:
                reg.append("R" + str(j) + '-DLR')
            min_DLR_reg = dlr_hourly[reg].min(axis = 1)
            DLR.append(list(min_DLR_reg))
               
    trans_lines["Hourly DLR"] = DLR
    
    #def write_table(id, values):
    for id_line in trans_lines.index:
        con = psycopg2.connect(host = db.credentials()['HOST'],
                               database = db.credentials()['POSTGRES_DB'],
                               user = db.credentials()['POSTGRES_USER'],
                               password = db.credentials()['POSTGRES_PASSWORD'],
                               port = db.credentials()['PORT']) 
        cur = con.cursor()
        sql = '''insert into grid.egon_pf_hv_line_timeseries
        (version, scn_name, line_id, s_max_pu) 
        values (%s, %s, %s, %s)'''      
        cur.execute(sql, (trans_lines.loc[id_line][2],
                          trans_lines.loc[id_line][3],
                          id_line,
                          list(trans_lines.loc[id_line][4])))
        con.commit()
        cur.close()
    
    return 0







    










